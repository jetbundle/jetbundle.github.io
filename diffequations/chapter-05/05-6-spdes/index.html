<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Section 5.6: SPDEs & Regularity Structures</title>
  <meta name="description" content="Hairer's regularity structures, renormalization">
  <!-- KaTeX Math Renderer - Reliable Client-Side Rendering -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">
<script>
(function() {
  var katexScript = document.createElement('script');
  katexScript.src = 'https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js';
  katexScript.integrity = 'sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8';
  katexScript.crossOrigin = 'anonymous';
  katexScript.async = false;
  katexScript.onload = function() {
    var renderScript = document.createElement('script');
    renderScript.src = 'https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js';
    renderScript.integrity = 'sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05';
    renderScript.crossOrigin = 'anonymous';
    renderScript.async = false;
    renderScript.onload = function() {
      function renderMath() {
        if (typeof renderMathInElement === 'undefined') return;
        try {
          renderMathInElement(document.body, {
            delimiters: [
              {left: '$$', right: '$$', display: true},
              {left: '$', right: '$', display: false},
              {left: '\\[', right: '\\]', display: true},
              {left: '\\(', right: '\\)', display: false}
            ],
            throwOnError: false,
            strict: false,
            trust: true,
            ignoredTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            ignoredClasses: ['no-math']
          });
        } catch (error) {
          console.error('KaTeX rendering error:', error);
        }
      }
      if (document.body) {
        renderMath();
      } else {
        document.addEventListener('DOMContentLoaded', renderMath);
      }
      window.addEventListener('load', function() {
        setTimeout(renderMath, 100);
      });
    };
    document.head.appendChild(renderScript);
  };
  document.head.appendChild(katexScript);
})();
</script>
  <link rel="stylesheet" href="/diffequations/styles.css">
  <script src="/diffequations/navigation-data.js"></script>
  <script src="/diffequations/manifold-background.js" defer></script>
</head>
<body>
  <main>
    <header>
      <h1>Section 5.6: SPDEs & Regularity Structures</h1>
      <p class="description">Hairer's regularity structures, renormalization</p>
    </header>
    <article>
<p>Regularity structures replace classical Taylor expansions with expansions in "noise monomials," transforming the analytic impossibility of singular products into a geometric study of decorated trees and structure groups.</p>
<h2>Introduction</h2>
<p>We now address the most profound analytical crisis in modern probability theory: the ill-posedness of nonlinear stochastic partial differential equations (SPDEs). In the previous sections, we established that stochastic trajectories are inherently rough, requiring the machinery of rough paths to define integration. However, when noise depends on both space and time—spacetime white noise—the singularity of the driving signal exceeds the capacity of classical distribution theory.</p>
<p>Standard analytical methods fail because the solution $u$ to a stochastic PDE is expected to have the same regularity as the driving noise $\xi$. If $\xi$ is a distribution rather than a function, the nonlinear term (such as $u \cdot \xi$ or $u^2$) requires the multiplication of distributions. As shown by Schwartz, there is no associative multiplication of distributions that extends the product of continuous functions. Consequently, equations such as the Kardar-Parisi-Zhang (KPZ) equation or the Parabolic Anderson Model are not merely hard to solve; they are mathematically meaningless without a renormalization procedure that subtracts infinite counterterms.</p>
<p>This section constructs the Theory of Regularity Structures, a framework that replaces the classical Taylor expansion with an expansion in terms of "noise monomials." This resolves the renormalization problem algebraically, transforming the analytic impossibility of singular products into a geometric study of decorated trees and structure groups.</p>
<h3>The Parabolic Anderson Model and the Product Problem</h3>
<p>We motivate the discussion with the Parabolic Anderson Model (PAM), which describes the evolution of a field $u(t,x)$ subject to diffusion and multiplicative growth proportional to a random potential $\xi$:</p>
$$\partial_t u = \Delta u + u \xi, \quad u(0,x) = u_0(x)$$

<p>where $\xi$ is spacetime white noise on the torus $\mathbb{T}^d$. The covariance of the noise is given by $\mathbb{E}[\xi(t,x)\xi(s,y)] = \delta(t-s)\delta(x-y)$. In the language of microlocal analysis (see Chapter 7.2), the noise $\xi$ has negative regularity. Specifically, in $d$ spatial dimensions, the realization of $\xi$ almost surely belongs to the Hölder-Besov space $\mathcal{C}^\alpha$ for any $\alpha < -d/2 - 1$.</p>
<p>For the parabolic operator $(\partial_t - \Delta)$, Schauder estimates suggest that the solution $u$ should have regularity two degrees higher than the noise. Thus, $u \in \mathcal{C}^{\alpha+2}$. To define the product $u \cdot \xi$ in the distributional sense, the sum of regularities must be positive: $(\alpha+2) + \alpha > 0$. This implies $\alpha > -1$.</p>
<p>This condition holds in one spatial dimension ($d=1$) only if the noise is extremely regularized, but fails for true white noise where $\alpha \approx -3/2$. In dimensions $d \ge 2$, the divergence is catastrophic. The product $u\xi$ contains "resonant" terms where the high frequencies of $u$ and $\xi$ reinforce each other to produce infinite averages.</p>
<p>To resolve this, we first examine the <strong>Wick Renormalization</strong> in the Gaussian context. If we approximate the noise by a smooth function $\xi_\varepsilon$ (via convolution with a mollifier), the solution $u_\varepsilon$ diverges as $\varepsilon \to 0$. However, the renormalized product $:u\xi:$ is defined by subtracting the mean value of the interaction, which corresponds to an infinite energy shift. This topic is covered extensively in Da Prato &amp; Debussche (2003) and serves as the precursor to the general algebraic theory.</p>
<h3>Regularity Structures: The Algebraic Foundation</h3>
<p>Martin Hairer's Theory of Regularity Structures generalizes the concept of a Taylor expansion. In classical calculus, a function $f$ is approximated near a point $x$ by a polynomial $P(y) = \sum a_n (y-x)^n$. The basis vectors $\{1, (y-x), (y-x)^2 \dots\}$ allow us to abstract "regularity" as coefficients in a vector space.</p>
<p>For SPDEs, the polynomial basis is insufficient because the solution locally looks like the noise and its iterated convolutions, not like a line or parabola. We therefore replace the polynomial ring with a <strong>Model Space</strong> $T$, a graded vector space spanned by <strong>decorated trees</strong>.</p>
<p>A <strong>Regularity Structure</strong> is a triple $\mathscr{T} = (A, T, G)$ consisting of:</p>
<p><strong>An Index Set</strong> $A \subset \mathbb{R}$: A set of homogeneities (degrees) bounded from below, describing the scaling behavior of the basis elements.</p>
<p><strong>The Model Space</strong> $T = \bigoplus_{\alpha \in A} T_\alpha$: A Banach space containing the abstract symbols representing the noise and its integrals. For the PAM, $T$ contains symbols $\Xi$ (representing $\xi$), $\mathcal{I}(\Xi)$ (representing the convolution with the heat kernel), and higher-order trees like $\Xi \mathcal{I}(\Xi)$.</p>
<p><strong>The Structure Group</strong> $G$: A group of linear transformations acting on $T$, which encodes the "re-centering" of expansions. This generalizes the translation of Taylor polynomials from one base point to another.</p>
<p>This algebraic framework is covered extensively in Hairer (2014).</p>
<h3>The Model and the Reconstruction Theorem</h3>
<p>The connection between the abstract algebra of trees and the analytic reality of distributions is established via the <strong>Model</strong>, denoted by $(\Pi, \Gamma)$.</p>
<p>The map $\Pi_x: T \to \mathcal{D}'(\mathbb{R}^{d+1})$ assigns to each abstract tree $\tau \in T$ a concrete distribution $\Pi_x \tau$ centered at spacetime point $x$. For example, if $\mathbf{1}$ is the unit element of the algebra, $\Pi_x \mathbf{1}$ is the constant function 1. If $\Xi$ is the noise symbol, $\Pi_x \Xi$ is the realization of the white noise itself.</p>
<p>Crucially, the Model must satisfy analytical bounds analogous to Hölder conditions. For a basis vector $\tau \in T_\alpha$, the concrete distribution $\Pi_x \tau$ must satisfy:</p>
$$\vert (\Pi_x \tau)(\varphi_x^\lambda) \vert \lesssim \lambda^\alpha$$

<p>where $\varphi_x^\lambda$ is a test function scaled by $\lambda$ and centered at $x$. This formalizes the idea that the "degree" $\alpha$ represents the local roughness of the fluctuation.</p>
<p>The <strong>Reconstruction Theorem</strong> is the fundamental result of the theory. It states that given a coherent family of local expansions satisfying the proper analytical bounds, there exists a unique global distribution $U$ that matches these local descriptions "to the order of the expansion." This generalizes the Whitney Extension Theorem to the setting of distributions and allows us to glue local noise approximations into a global solution.</p>
$$\vert (U - \Pi_x U(x))(\varphi_x^\lambda) \vert \lesssim \lambda^\gamma$$

<p>where $\gamma$ is the order of the expansion. This theorem allows us to define the "solution" map $\mathcal{S}$ which takes a Model and produces the solution to the fixed-point equation.</p>
<h3>Renormalization Group and Fixed Point Problems</h3>
<p>The physical content of the theory appears in the renormalization group flow. The construction of the canonical Model $(\Pi, \Gamma)$ based on the raw noise $\xi$ is often ill-defined because the product of distributions $\Pi_x(\tau_1) \cdot \Pi_x(\tau_2)$ may not exist.</p>
<p>We introduce a <strong>Renormalization Group</strong> $\mathcal{R}$ acting on the space of Models. The operation $M \mapsto M^R$ transforms the model by subtracting polynomial parts from the singular trees. This algebraic subtraction corresponds exactly to the infinite counterterms required in the Lagrangian formulation of quantum field theory (Chapter 1.7).</p>
<p>The solution to the singular SPDE is then found via a fixed-point argument in the space of "modeled distributions" $\mathcal{D}^\gamma$, spaces of functions that look locally like elements of the Model $T$. The abstract fixed point equation is:</p>
$$U = \mathcal{K}_\gamma (\Xi + U \Xi) + P$$

<p>where $\mathcal{K}_\gamma$ is the lift of the heat kernel to the regularity structure and $P$ represents polynomial initial data.</p>
<p>By proving that the renormalization group flow possesses a fixed point (or a coherent limit), we establish the existence of solutions to the original SPDE. For the KPZ equation, this explains the "universality" of the scaling limits: the equation is the fixed point of the renormalization flow under the scaling transformation.</p>
<p>The development of this theory demonstrates that the divergences encountered in Chapter 1 are not analytical failures, but rather indications that we were working in the wrong vector space. The solution lives not in a space of functions, but in a space of distributions modeled on a specific Hopf algebra of trees. This prepares us for the final ascent in Chapter 7, where we will see that these "trees" and "counterterms" are manifestations of the alien calculus of resurgence.</p>
<h2>Complete Examples</h2>
<h3>Example 5.6.1: The Parabolic Anderson Model—Wick Renormalization</h3>
<p><strong>Problem:</strong> Consider the 1D Parabolic Anderson Model on the torus $\mathbb{T} = [0,2\pi]$:</p>
$$\partial_t u = \partial_{xx} u + u \xi, \quad u(0,x) = 1$$

<p>where $\xi(t,x)$ is spacetime white noise with $\mathbb{E}[\xi(t,x)\xi(s,y)] = \delta(t-s)\delta(x-y)$.</p>
<p><strong>Solution:</strong></p>
<p>Approximate $\xi$ by mollified noise $\xi_\varepsilon(t,x) = \xi * \rho_\varepsilon$, where $\rho_\varepsilon(z) = \varepsilon^{-2} \rho(z/\varepsilon)$ and $\int \rho = 1$. The mild solution satisfies the fixed-point equation:</p>
$$
u_\varepsilon(t,x) = 1 + \int_0^t \int_{\mathbb{T}} p_{t-s}(x-y) u_\varepsilon(s,y) \xi_\varepsilon(s,y) \, dy \, ds
$$

<p>where $p_t(x) = \frac{1}{\sqrt{4\pi t}} e^{-x^2/(4t)}$ is the heat kernel.</p>
<p>Picard iteration begins with $u_\varepsilon^{(0)}(t,x) = 1$:</p>
$$
u_\varepsilon^{(1)}(t,x) = 1 + \int_0^t \int p_{t-s}(x-y) \xi_\varepsilon(s,y) \, dy \, ds
$$

$$
u_\varepsilon^{(2)}(t,x) = 1 + \int_0^t \int p_{t-s}(x-y) u_\varepsilon^{(1)}(s,y) \xi_\varepsilon(s,y) \, dy \, ds
$$

<p>The first iterate (linear response) is:</p>
$$
u_\varepsilon^{(1)}(t,x) = 1 + \mathcal{I}(\xi_\varepsilon)(t,x)
$$

<p>where $\mathcal{I}(f)(t,x) = \int_0^t \int p_{t-s}(x-y) f(s,y) \, dy \, ds$. The second iterate is:</p>
$$
u_\varepsilon^{(2)}(t,x) = 1 + \mathcal{I}(\xi_\varepsilon) + \mathcal{I}(\xi_\varepsilon \cdot \mathcal{I}(\xi_\varepsilon))
$$

<p>Computing the variance $\mathbb{E}[u_\varepsilon^{(2)}(t,x)^2]$:</p>
$$
\mathbb{E}[u_\varepsilon^{(2)}]^2 = 1 + 2\mathbb{E}[\mathcal{I}(\xi_\varepsilon)] + \mathbb{E}[\mathcal{I}(\xi_\varepsilon)^2] + 2\mathbb{E}[\mathcal{I}(\xi_\varepsilon \cdot \mathcal{I}(\xi_\varepsilon))] + \mathbb{E}[\mathcal{I}(\xi_\varepsilon \cdot \mathcal{I}(\xi_\varepsilon))^2]
$$

<p>The critical term is $\mathbb{E}[\mathcal{I}(\xi_\varepsilon)^2]$:</p>
$$
\mathbb{E}[\mathcal{I}(\xi_\varepsilon)^2] = \mathbb{E}\left[\int_0^t \int_0^t \int_{\mathbb{T}^2} p_{t-s}(x-y) p_{t-r}(x-z) \xi_\varepsilon(s,y) \xi_\varepsilon(r,z) \, dy \, dz \, ds \, dr\right]
$$

<p>Using the white noise covariance:</p>
$$
\mathbb{E}[\mathcal{I}(\xi_\varepsilon)^2] = \int_0^t \int_{\mathbb{T}} p_{t-s}(x-y)^2 * \rho_\varepsilon * \rho_\varepsilon(0) \, dy \, ds
$$

<p>As $\varepsilon \to 0$, $\rho_\varepsilon * \rho_\varepsilon(0) \sim \varepsilon^{-2}$, yielding:</p>
$$
\mathbb{E}[\mathcal{I}(\xi_\varepsilon)^2] \sim \frac{C}{\varepsilon}
$$

<p>The variance diverges as $\varepsilon^{-1}$, revealing the fundamental singularity that requires renormalization.</p>
<p>Wick renormalization defines the renormalized noise:</p>
$$
\xi_\varepsilon^\text{ren}(t,x) = \xi_\varepsilon(t,x) - \mathbb{E}[\xi_\varepsilon(t,x)^2] = \xi_\varepsilon(t,x) - \frac{C}{\varepsilon}
$$

<p>The renormalized solution is:</p>
$$
u_\varepsilon^\text{ren}(t,x) = 1 + \int_0^t \int p_{t-s}(x-y) u_\varepsilon^\text{ren}(s,y) \xi_\varepsilon^\text{ren}(s,y) \, dy \, ds
$$

<p>This yields $\mathbb{E}[u_\varepsilon^\text{ren}(t,x)] \to 1$ and $\text{Var}(u_\varepsilon^\text{ren}) \to \text{finite limit}$, demonstrating that subtracting the divergent mean restores well-posedness.</p>
<h3>Example 5.6.2: Regularity Structure for PAM—Tree Construction</h3>
<p><strong>Goal:</strong> Construct the regularity structure for PAM and solve the fixed-point equation symbolically.</p>
<p><strong>Solution:</strong></p>
<p>Define the index set and generators. The index set is $A = \{0, -1/2 - \kappa, 1/2 - \kappa\} \cup \{\vert \tau \vert : \tau \in T\}$ where $\kappa > 0$ is small.</p>
<p>Abstract symbols: $\mathbf{1} \in T_0$ (constant function), $\Xi \in T_{-1/2-\kappa}$ (white noise), and $\mathcal{I}(\tau) \in T_{\vert \tau \vert + 2}$ (integration against heat kernel).</p>
<p>Generate trees up to order 3. Level 1: $\Xi \in T_{-1/2-\kappa}$. Level 2: $\mathcal{I}(\Xi) \in T_{3/2-\kappa}$. Level 3: $\mathcal{I}(\Xi \cdot \mathcal{I}(\Xi)) \in T_{5/2-2\kappa}$ and $\mathcal{I}(\Xi)^2 \in T_{3-\kappa}$. Level 4 (relevant for nonlinearity): $\mathcal{I}(\Xi \cdot \mathcal{I}(\Xi \cdot \mathcal{I}(\Xi))) \in T_{7/2-3\kappa}$.</p>
<p>The structure group $G$ acts by "re-centering." For a tree $\tau$, the action is $(\Pi_x \tau)(z) = \Pi_x \tau(z-x) + \text{polynomial correction}$. Explicit computation for $\mathcal{I}(\Xi)$: $[\Gamma_x \mathcal{I}(\Xi)]_z = \Pi_z \mathcal{I}(\Xi) - \Pi_x \mathcal{I}(\Xi)$.</p>
<p>The fixed-point equation in the regularity structure is $U = \mathcal{I}(\Xi U) + \mathbf{1}$. Expanding in the regularity structure:</p>
$$
   U = u_{-1/2-\kappa} \Xi + u_{3/2-\kappa} \mathcal{I}(\Xi) + u_{5/2-2\kappa} \mathcal{I}(\Xi \cdot \mathcal{I}(\Xi)) + \cdots
   $$

<p>Substituting and collecting terms: at order $-1/2-\kappa$, $u_{-1/2-\kappa} = 0$ (no noise in solution); at order $3/2-\kappa$, $u_{3/2-\kappa} \mathcal{I}(\Xi) = \mathcal{I}(\Xi)$; at order $5/2-2\kappa$, $u_{5/2-2\kappa} \mathcal{I}(\Xi \cdot \mathcal{I}(\Xi)) = \mathcal{I}(\Xi \cdot \mathcal{I}(\Xi))$. Remarkably, $u_\alpha = 1$ for all trees appearing in the expansion, demonstrating the universality of the tree structure.</p>
<p>For the renormalization of the quadratic term, the problematic term $\Xi \cdot \mathcal{I}(\Xi)$ has regularity $\vert \Xi \cdot \mathcal{I}(\Xi) \vert = -1/2-\kappa + 3/2-\kappa = 1-2\kappa > 0$. However, $\mathbb{E}[\Xi \cdot \mathcal{I}(\Xi)] = \infty$. Define the renormalized version:</p>
$$
   \Xi \cdot \mathcal{I}(\Xi) \mapsto \Xi \cdot \mathcal{I}(\Xi) - C
   $$

<p>where $C = \lim_{\varepsilon \to 0} \mathbb{E}[\Xi_\varepsilon \cdot \mathcal{I}(\Xi_\varepsilon)]$. This subtraction removes the infinite mean, making the product well-defined in the limit.</p>
<h3>Example 5.6.3: KPZ Equation—Universality and Subcriticality</h3>
<p><strong>Problem:</strong> Solve the KPZ equation in 1D:</p>
$$\partial_t h = \frac{1}{2} \partial_{xx} h + \frac{1}{2} (\partial_x h)^2 + \xi$$

<p><strong>Solution:</strong></p>
<p>The Cole-Hopf transformation sets $Z = e^h$. Then:</p>
$$
\partial_t Z = \frac{1}{2} \partial_{xx} Z + Z \xi
$$

<p>This is exactly the PAM equation. The solution is $h(t,x) = \log Z(t,x)$.</p>
<p>For the regularity structure construction, KPZ has parabolic scaling $[t] = 2$, $[x] = 1$, $[\xi] = -3/2-\kappa$, $[h] = -1/2-\kappa$. The trees are: $\Xi \in T_{-3/2-\kappa}$, $\mathcal{I}(\Xi) \in T_{1/2-\kappa}$, $\mathcal{I}(\Xi^2) \in T_{2-2\kappa}$, and $\mathcal{I}(\partial_x \mathcal{I}(\Xi) \cdot \partial_x \mathcal{I}(\Xi)) \in T_{1/2-2\kappa}$.</p>
<p>For the subcriticality check, consider the fixed-point equation $H = \mathcal{I}(\Xi + \frac{1}{2} (\partial_x H)^2)$:</p>
<p>| Term \vert Regularity \vert Subcritical? |<br />
|------\vert------------\vert--------------|<br />
| $\Xi$ \vert $-3/2-\kappa$ \vert Base case |<br />
| $\partial_x H$ \vert $-3/2-\kappa$ \vert Derivative |<br />
| $(\partial_x H)^2$ \vert $-3-\kappa$ \vert Quadratic |<br />
| $\mathcal{I}((\partial_x H)^2)$ \vert $1-\kappa$ \vert Integration |</p>
<p>Since $1-\kappa > -3/2-\kappa$, each iteration improves regularity, ensuring convergence of the fixed-point iteration.</p>
<p>Renormalization constants are computed from divergent expectations:</p>
$$
\mathbb{E}[\Xi^2] = \infty \quad \Rightarrow \quad \Xi^2 \mapsto \Xi^2 - C_0
$$

$$
\mathbb{E}[\partial_x \mathcal{I}(\Xi) \cdot \partial_x \mathcal{I}(\Xi)] = \infty \quad \Rightarrow \quad \text{requires } C_1
$$

<p>For universality, consider the Edwards-Wilkinson equation with nonlinearities:</p>
$$
\partial_t h^\lambda = \Delta h^\lambda + \lambda \mathcal{N}(h^\lambda) + \xi
$$

<p>For $\mathcal{N}(h) = (\partial_x h)^2$, the scaling limit as mesh $\to 0$ converges to KPZ. The proof sketch: rescale $h^\lambda(t,x) = \varepsilon^{-1/2} h(\varepsilon^{-2}t, \varepsilon^{-1}x)$; the nonlinear term scales as $\varepsilon^{-1/2}$; the regularity structure absorbs all $\lambda$-dependence into renormalization constants; the fixed point is universal. This demonstrates that KPZ emerges as the universal scaling limit of a wide class of stochastic growth models, independent of the specific nonlinearity chosen.</p>
<h3>Example 5.6.4: Explicit Tree Expansion—2D PAM Failure and Rescue</h3>
<p><strong>Problem:</strong> Why does 2D PAM require more sophisticated renormalization?</p>
<p><strong>Solution:</strong></p>
<p>For regularity computation in 2D, the scaling is $[t] = 2$, $[x] = 1$, $\xi \in C^{-2-\kappa}$. The critical product is:</p>
$$
\vert \Xi \cdot \mathcal{I}(\Xi) \vert = -2-\kappa + 2-\kappa = -2\kappa \approx 0
$$

<p>The product is at the regularity threshold, making the situation critical.</p>
<p>For explicit divergence computation, the mollified expectation is:</p>
$$
\mathbb{E}[\Xi_\varepsilon \cdot \mathcal{I}(\Xi_\varepsilon)(0,0)] = \int_0^T \int_{\mathbb{T}^2} p_t(y)^2 \rho_\varepsilon * \rho_\varepsilon(0) \, dy \, dt
$$

<p>where $p_t(y) = \frac{1}{4\pi t} e^{-\vert y \vert^2/(4t)}$. The asymptotic is:</p>
$$
\int_{\mathbb{T}^2} p_t(y)^2 \, dy \sim \frac{1}{4\pi t}
$$

<p>Thus:</p>
$$
\mathbb{E}[\Xi_\varepsilon \cdot \mathcal{I}(\Xi_\varepsilon)] \sim \frac{\log(1/\varepsilon)}{4\pi}
$$

<p>The divergence is logarithmic, not a power law, reflecting the marginal nature of the 2D case.</p>
<p>The regularity structure rescue introduces auxiliary trees:</p>
$$
\tau_1 = \Xi, \quad \tau_2 = \mathcal{I}(\tau_1), \quad \tau_3 = \mathcal{I}(\tau_1 \tau_2)
$$

<p>The renormalized structure is:</p>
$$
\tau_3 \mapsto \mathcal{I}(\tau_1 \tau_2 - C \log(1/\varepsilon) \mathbf{1})
$$

<p>For fixed-point iteration with renormalization: $U^{(1)} = \mathcal{I}(\Xi)$, $U^{(2)} = \mathcal{I}(\Xi U^{(1)}) = \mathcal{I}(\Xi \cdot \mathcal{I}(\Xi))$, and $U^{(3)} = \mathcal{I}(\Xi U^{(2)}) = \mathcal{I}(\Xi \cdot \mathcal{I}(\Xi \cdot \mathcal{I}(\Xi)))$. The renormalized version is:</p>
$$
U^{(3)\text{ren}} = \mathcal{I}\Big(\Xi \cdot \big(\mathcal{I}(\Xi \cdot \mathcal{I}(\Xi)) - C_1 \log(1/\varepsilon)\big)\Big)
$$

<p>For the convergence proof in the modeled distribution space $\mathcal{D}^\gamma$ with $\gamma = -1/2-\kappa$:</p>
<p>| Iteration \vert Regularity Gain \vert Renormalized Term |<br />
|-----------\vert----------------\vert-------------------|<br />
| $U^{(1)}$ \vert $1/2-\kappa$ \vert None |<br />
| $U^{(2)}$ \vert $3/2-2\kappa$ \vert $C_0$ |<br />
| $U^{(3)}$ \vert $5/2-3\kappa$ \vert $C_1 \log(1/\varepsilon)$ |</p>
<p>Each iteration improves regularity by $2$, while renormalization subtracts exactly the divergent part, ensuring convergence via a contraction mapping argument.</p>
<h3>Example 5.6.5: Structure Group Computation—Explicit Model Construction</h3>
<p><strong>Goal:</strong> Construct the explicit model $(\Pi, \Gamma)$ for PAM.</p>
<p><strong>Solution:</strong></p>
<p>Define the realization $\Pi$ for a fixed noise realization $\xi$:</p>
$$
\Pi(\mathbf{1}) = 1, \quad \Pi(\Xi) = \xi, \quad \Pi(\mathcal{I}(\tau))(t,x) = \int_0^t \int p_{t-s}(x-y) \Pi(\tau)(s,y) \, dy \, ds
$$

<p>For the structure group element, translation by $z = (t_0,x_0)$:</p>
$$
\Gamma_z \tau = \sum_{\sigma \preceq \tau} \Pi_z(\sigma) \cdot R_{z,\tau/\sigma}
$$

<p>where $R_{z,\tau}$ is the "remainder" term. Explicit computation for $\mathcal{I}(\Xi)$:</p>
$$
\Gamma_{(t_0,x_0)} \mathcal{I}(\Xi) = \Pi_{(t_0,x_0)}(\mathcal{I}(\Xi)) - \Pi_{(0,0)}(\mathcal{I}(\Xi))
$$

<p>The model property requires $\Pi_z \Gamma_z \tau = \Pi_z \tau$ for all $z$. Verification for $\mathcal{I}(\Xi^2)$: compute $\Pi_z(\mathcal{I}(\Xi^2))$, apply $\Gamma_z$ subtracting local expectations, and verify translation invariance.</p>
<p>For the reconstruction theorem application, given local expansions:</p>
$$
U(z) = \sum_{\vert \tau \vert < \gamma} \langle U \rangle_z(\tau) \Pi_z(\tau) + R_z
$$

<p>The theorem states that there exists a unique $U \in \mathcal{D}'$ such that:</p>
$$
\vert U(\phi_z^\lambda) - \sum_{\vert \tau \vert < \gamma} \langle U \rangle_z(\tau) \Pi_z(\tau)(\phi_z^\lambda) \vert \lesssim \lambda^\gamma
$$

<p>The proof sketch involves local Whitney-type estimates, gluing via partition of unity, and consistency via structure group action. This theorem provides the rigorous foundation for reconstructing global distributions from local tree expansions.</p>
<h2>References</h2>
<ul>
<li>Da Prato, G., &amp; Debussche, A. (2003). <em>Strong solutions to the stochastic quantization equations</em>. Annals of Probability.</li>
<li>Friz, P. K., &amp; Hairer, M. (2014). <em>A Course on Rough Paths</em>. Springer.</li>
<li>Hairer, M. (2014). <em>A Theory of Regularity Structures</em>. Inventiones mathematicae.</li>
</ul>
<h2>Navigation</h2>
<hr />
<h2>Related Sections</h2>
<ul>
<li><a href="{{ '/diffequations/chapter-05/05-5-fractional-calculus/' \vert relative_url }}">Previous Section: 5.5 Fractional Calculus &amp; Nonlocal Operators</a></li>
<li><a href="{{ '/diffequations/chapter-05/05-7-kinetic-theory/' \vert relative_url }}">Next Section: 5.7 Kinetic Theory &amp; Mean-Field Games</a></li>
<li><a href="{{ '/diffequations/chapter-05/' \vert relative_url }}">Chapter Index</a></li>
<li><a href="{{ '/diffequations/' \vert relative_url }}">Full Table of Contents</a></li>
</ul>
    </article>
  </main>
  <script src="/diffequations/navigation.js"></script>

  <!-- Python/Plotly Widget System - Load after content -->
  <script>
    // Lazy load Plotly.js after page is fully loaded
    window.addEventListener('load', function() {
      var plotlyScript = document.createElement('script');
      plotlyScript.src = 'https://cdn.plot.ly/plotly-2.27.0.min.js';
      plotlyScript.charset = 'utf-8';
      plotlyScript.async = true;
      document.body.appendChild(plotlyScript);
    });
  </script>

  <!-- Widget Engine Scripts - Load with defer to not block rendering -->
  <script defer src="/diffequations/js/textbook-engine.js"></script>
  <script defer src="/diffequations/js/widget-engine.js"></script>
</body>
</html>